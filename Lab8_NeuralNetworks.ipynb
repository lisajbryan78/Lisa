{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Netoworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for this chapter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the hypothetical bank data in on consumers’ use of credit card credit facilities. Import dataset _creditcard.csv_. Use Python program to illustrate one pass through a simple neural network (Randomly generate initial weight values)\n",
    "\n",
    "_Years: number of years the customer has been with the bank_\n",
    "\n",
    "_Salary: customer’s salary (in thousands of dollars)_\n",
    "\n",
    "_Used Credit: 1 = customer has left an unpaid credit card balance at the end of at least one month in the prior year, 0 = balance was paid off at the end of each month_\n",
    "\n",
    "__Data Preprocessing.__ The dataset is too small, we will not split the data. We are using the whole set as a training set to estabish our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 3)\n",
      "Years          6\n",
      "Salary         6\n",
      "Used_Credit    6\n",
      "dtype: int64\n",
      "             count       mean        std   min    25%   50%    75%    max\n",
      "Years          6.0   7.833333   6.968979   1.0   3.25   5.0  12.75   18.0\n",
      "Salary         6.0  76.000000  26.608269  43.0  56.00  76.5  93.25  112.0\n",
      "Used_Credit    6.0   0.500000   0.547723   0.0   0.00   0.5   1.00    1.0\n"
     ]
    }
   ],
   "source": [
    "# Load the data into creditcard_df dataframe\n",
    "# Use critical functions to explore the dataframe using print() to show results\n",
    "\n",
    "creditcard_df=pd.read_csv(\"C:/Users/lisaj/OneDrive/Documents/Documents/MIS 536/Module8Datasets/creditcard.csv\")\n",
    "\n",
    "print(creditcard_df.shape)\n",
    "print(creditcard_df.count())\n",
    "print(creditcard_df.describe().transpose())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Years  Salary\n",
      "0      4      43\n",
      "1     18      65\n",
      "2      1      53\n",
      "3      3      95\n",
      "4     15      88\n",
      "5      6     112 0    0\n",
      "1    1\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "5    1\n",
      "Name: Used_Credit, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# construct the dataset: predictors(X) and outcome(y)\n",
    "# print out results to varify\n",
    "\n",
    "X=creditcard_df.drop('Used_Credit', axis='columns')\n",
    "y=creditcard_df['Used_Credit']\n",
    "\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data uisng standard scalar.\n",
    "# Do we need to standardize both predictors and outcome or just one of thoese two?\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X)\n",
    "X=scaler.transform(X)\n",
    "\n",
    "# Both predictors need to be standardized since they are both continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=3, random_state=1,\n",
       "              solver='lbfgs')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataset is too small to partition into training set and validation set. We will use the whole dataset for training\n",
    "# Multi-layer Perceptron classifier: one layer with 3 hidden nodes, set the activation function to be logistic function, solver to be lbfgs\n",
    "\n",
    "mlp=MLPClassifier(hidden_layer_sizes=(3), activation='logistic', solver='lbfgs', random_state=1)\n",
    "\n",
    "mlp.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "predictions=mlp.predict(X)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y, predictions))\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer 2 => 3\n",
      " Intercepts:\n",
      "  [-0.09991553 -0.99226352  2.54413658]\n",
      " Weights:\n",
      "  [-2.79453344  4.31675176 -6.27991604]\n",
      "  [-1.42873363  2.91069399 -4.7071766 ]\n",
      "\n",
      "Output layer 3 => 1\n",
      " Intercepts:\n",
      "  [3.19201542]\n",
      " Weights:\n",
      "  [-4.50433939]\n",
      "  [6.74961315]\n",
      "  [-8.33092289]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Network structure\n",
    "# Hint: sample code given in in class exercise\n",
    "\n",
    "for i, (weights, intercepts) in enumerate(zip(mlp.coefs_, mlp.intercepts_)):\n",
    "    print('Hidden layer' if i == 0 else 'Output layer', '{0[0]} => {0[1]}'.format(weights.shape))\n",
    "    print(' Intercepts:\\n ', intercepts)\n",
    "    print(' Weights:')\n",
    "    for weight in weights:\n",
    "        print(' ', weight)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  Used_Credit  Predicted  index         1         2\n",
      "0      0            0          0      0  0.999926  0.000074\n",
      "1      1            1          1      1  0.000058  0.999942\n",
      "2      2            0          0      2  0.999931  0.000069\n",
      "3      3            0          0      3  0.999341  0.000659\n",
      "4      4            1          1      4  0.000055  0.999945\n",
      "5      5            1          1      5  0.000433  0.999567\n"
     ]
    }
   ],
   "source": [
    "# Predictions: merge predicted classification and the probability to each class into the orignal table\n",
    "\n",
    "temp=pd.concat([pd.DataFrame(y).reset_index(), pd.DataFrame(predictions, columns=['Predicted'])], axis=1)\n",
    "predict=pd.concat([temp, pd.DataFrame(mlp.predict_proba(X), columns=[1,2]).reset_index()], axis=1)\n",
    "\n",
    "print(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [0 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         3\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         6\n",
      "   macro avg       1.00      1.00      1.00         6\n",
      "weighted avg       1.00      1.00      1.00         6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the confusion_matrix and classification_report\n",
    "\n",
    "print(confusion_matrix(y, predictions))\n",
    "print(classification_report(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret your results:\n",
    "\n",
    "#According to the confusion matrix, three customers had at a credit card balance at the end of at least one month in the prior year. Three customers did not have a balance at the end of the month\n",
    "#in the previous year on their credit card.\n",
    "\n",
    "#The classification report indicates that the predictions in the model I created were 100% accurate. \n",
    "\n",
    "# Lesson learned from this excercise:\n",
    "\n",
    "#In this exercise, I learned how to create a multilayer perceptron model,  merge the predicted classification and probability of each class with the original table, and create and \n",
    "# interpret a classification matrix and classification report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Car Sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the data on used cars (_toyotacorolla.csv_) with 1436 records and details on 38 attributes, including Price, Age, KM, HP, and other specifcations. The goal is to predict the price of a used Toyota Corolla based on its specifcations.\n",
    "\n",
    "Use predictors Age_08_04, KM, Fuel_Type, HP, Automatic, Doors, Quarterly_Tax, Mfr_Guarantee, Guarantee_Period, Airco, Automatic_airco, CD_Player, Powered_Windows, Sport_Model, and Tow_Bar.\n",
    "\n",
    "__Data Preprocessing.__ TUse the scikit-learn transformer _MinMaxScaler()_ to scale the data to the range [0, 1]. Use separate transformer for the input and output data. To create the dummy variables, use the pandas function _pd.get_dummies()_. Partition the data into training (60%) and validation (40%) sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 39)\n",
      "                    count          mean           std     min       25%  \\\n",
      "Id                 1436.0    721.555014    416.476890     1.0    361.75   \n",
      "Price              1436.0  10730.824513   3626.964585  4350.0   8450.00   \n",
      "Age_08_04          1436.0     55.947075     18.599988     1.0     44.00   \n",
      "Mfg_Month          1436.0      5.548747      3.354085     1.0      3.00   \n",
      "Mfg_Year           1436.0   1999.625348      1.540722  1998.0   1998.00   \n",
      "KM                 1436.0  68533.259749  37506.448872     1.0  43000.00   \n",
      "HP                 1436.0    101.502089     14.981080    69.0     90.00   \n",
      "Met_Color          1436.0      0.674791      0.468616     0.0      0.00   \n",
      "Automatic          1436.0      0.055710      0.229441     0.0      0.00   \n",
      "CC                 1436.0   1576.855850    424.386770  1300.0   1400.00   \n",
      "Doors              1436.0      4.033426      0.952677     2.0      3.00   \n",
      "Cylinders          1436.0      4.000000      0.000000     4.0      4.00   \n",
      "Gears              1436.0      5.026462      0.188510     3.0      5.00   \n",
      "Quarterly_Tax      1436.0     87.122563     41.128611    19.0     69.00   \n",
      "Weight             1436.0   1072.459610     52.641120  1000.0   1040.00   \n",
      "Mfr_Guarantee      1436.0      0.409471      0.491907     0.0      0.00   \n",
      "BOVAG_Guarantee    1436.0      0.895543      0.305959     0.0      1.00   \n",
      "Guarantee_Period   1436.0      3.815460      3.011025     3.0      3.00   \n",
      "ABS                1436.0      0.813370      0.389750     0.0      1.00   \n",
      "Airbag_1           1436.0      0.970752      0.168559     0.0      1.00   \n",
      "Airbag_2           1436.0      0.722841      0.447751     0.0      0.00   \n",
      "Airco              1436.0      0.508357      0.500104     0.0      0.00   \n",
      "Automatic_airco    1436.0      0.056407      0.230786     0.0      0.00   \n",
      "Boardcomputer      1436.0      0.294568      0.456007     0.0      0.00   \n",
      "CD_Player          1436.0      0.218663      0.413483     0.0      0.00   \n",
      "Central_Lock       1436.0      0.580084      0.493717     0.0      0.00   \n",
      "Powered_Windows    1436.0      0.561978      0.496317     0.0      0.00   \n",
      "Power_Steering     1436.0      0.977716      0.147657     0.0      1.00   \n",
      "Radio              1436.0      0.146240      0.353469     0.0      0.00   \n",
      "Mistlamps          1436.0      0.256964      0.437111     0.0      0.00   \n",
      "Sport_Model        1436.0      0.300139      0.458478     0.0      0.00   \n",
      "Backseat_Divider   1436.0      0.770195      0.420854     0.0      1.00   \n",
      "Metallic_Rim       1436.0      0.204735      0.403649     0.0      0.00   \n",
      "Radio_cassette     1436.0      0.145543      0.352770     0.0      0.00   \n",
      "Parking_Assistant  1436.0      0.002786      0.052723     0.0      0.00   \n",
      "Tow_Bar            1436.0      0.277855      0.448098     0.0      0.00   \n",
      "\n",
      "                       50%       75%       max  \n",
      "Id                   721.5   1081.25    1442.0  \n",
      "Price               9900.0  11950.00   32500.0  \n",
      "Age_08_04             61.0     70.00      80.0  \n",
      "Mfg_Month              5.0      8.00      12.0  \n",
      "Mfg_Year            1999.0   2001.00    2004.0  \n",
      "KM                 63389.5  87020.75  243000.0  \n",
      "HP                   110.0    110.00     192.0  \n",
      "Met_Color              1.0      1.00       1.0  \n",
      "Automatic              0.0      0.00       1.0  \n",
      "CC                  1600.0   1600.00   16000.0  \n",
      "Doors                  4.0      5.00       5.0  \n",
      "Cylinders              4.0      4.00       4.0  \n",
      "Gears                  5.0      5.00       6.0  \n",
      "Quarterly_Tax         85.0     85.00     283.0  \n",
      "Weight              1070.0   1085.00    1615.0  \n",
      "Mfr_Guarantee          0.0      1.00       1.0  \n",
      "BOVAG_Guarantee        1.0      1.00       1.0  \n",
      "Guarantee_Period       3.0      3.00      36.0  \n",
      "ABS                    1.0      1.00       1.0  \n",
      "Airbag_1               1.0      1.00       1.0  \n",
      "Airbag_2               1.0      1.00       1.0  \n",
      "Airco                  1.0      1.00       1.0  \n",
      "Automatic_airco        0.0      0.00       1.0  \n",
      "Boardcomputer          0.0      1.00       1.0  \n",
      "CD_Player              0.0      0.00       1.0  \n",
      "Central_Lock           1.0      1.00       1.0  \n",
      "Powered_Windows        1.0      1.00       1.0  \n",
      "Power_Steering         1.0      1.00       1.0  \n",
      "Radio                  0.0      0.00       1.0  \n",
      "Mistlamps              0.0      1.00       1.0  \n",
      "Sport_Model            0.0      1.00       1.0  \n",
      "Backseat_Divider       1.0      1.00       1.0  \n",
      "Metallic_Rim           0.0      0.00       1.0  \n",
      "Radio_cassette         0.0      0.00       1.0  \n",
      "Parking_Assistant      0.0      0.00       1.0  \n",
      "Tow_Bar                0.0      1.00       1.0  \n",
      "\n",
      "\n",
      " Id                   float64\n",
      "Model                 object\n",
      "Price                float64\n",
      "Age_08_04            float64\n",
      "Mfg_Month            float64\n",
      "Mfg_Year             float64\n",
      "KM                   float64\n",
      "Fuel_Type             object\n",
      "HP                   float64\n",
      "Met_Color            float64\n",
      "Color                 object\n",
      "Automatic            float64\n",
      "CC                   float64\n",
      "Doors                float64\n",
      "Cylinders            float64\n",
      "Gears                float64\n",
      "Quarterly_Tax        float64\n",
      "Weight               float64\n",
      "Mfr_Guarantee        float64\n",
      "BOVAG_Guarantee      float64\n",
      "Guarantee_Period     float64\n",
      "ABS                  float64\n",
      "Airbag_1             float64\n",
      "Airbag_2             float64\n",
      "Airco                float64\n",
      "Automatic_airco      float64\n",
      "Boardcomputer        float64\n",
      "CD_Player            float64\n",
      "Central_Lock         float64\n",
      "Powered_Windows      float64\n",
      "Power_Steering       float64\n",
      "Radio                float64\n",
      "Mistlamps            float64\n",
      "Sport_Model          float64\n",
      "Backseat_Divider     float64\n",
      "Metallic_Rim         float64\n",
      "Radio_cassette       float64\n",
      "Parking_Assistant    float64\n",
      "Tow_Bar              float64\n",
      "dtype: object\n",
      "\n",
      "\n",
      " Id                   1436\n",
      "Model                1436\n",
      "Price                1436\n",
      "Age_08_04            1436\n",
      "Mfg_Month            1436\n",
      "Mfg_Year             1436\n",
      "KM                   1436\n",
      "Fuel_Type            1436\n",
      "HP                   1436\n",
      "Met_Color            1436\n",
      "Color                1436\n",
      "Automatic            1436\n",
      "CC                   1436\n",
      "Doors                1436\n",
      "Cylinders            1436\n",
      "Gears                1436\n",
      "Quarterly_Tax        1436\n",
      "Weight               1436\n",
      "Mfr_Guarantee        1436\n",
      "BOVAG_Guarantee      1436\n",
      "Guarantee_Period     1436\n",
      "ABS                  1436\n",
      "Airbag_1             1436\n",
      "Airbag_2             1436\n",
      "Airco                1436\n",
      "Automatic_airco      1436\n",
      "Boardcomputer        1436\n",
      "CD_Player            1436\n",
      "Central_Lock         1436\n",
      "Powered_Windows      1436\n",
      "Power_Steering       1436\n",
      "Radio                1436\n",
      "Mistlamps            1436\n",
      "Sport_Model          1436\n",
      "Backseat_Divider     1436\n",
      "Metallic_Rim         1436\n",
      "Radio_cassette       1436\n",
      "Parking_Assistant    1436\n",
      "Tow_Bar              1436\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "# explore the data\n",
    "\n",
    "toyotacorolla_df=pd.read_csv(\"C:/Users/lisaj/OneDrive/Documents/Documents/MIS 536/Module8Datasets/toyotacorolla.csv\")\n",
    "\n",
    "print(toyotacorolla_df.shape)\n",
    "print(toyotacorolla_df.describe().transpose())\n",
    "\n",
    "print('\\n\\n', toyotacorolla_df.dtypes)\n",
    "print('\\n\\n', toyotacorolla_df.count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CNG  Diesel  Petrol\n",
      "0    0       0       0\n",
      "1    0       1       0\n",
      "2    0       0       0\n",
      "          Id                                              Model    Price  \\\n",
      "0        NaN                                                NaN      NaN   \n",
      "1        1.0      TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500.0   \n",
      "2        NaN                                                NaN      NaN   \n",
      "3        2.0      TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750.0   \n",
      "4        NaN                                                NaN      NaN   \n",
      "...      ...                                                ...      ...   \n",
      "2867  1440.0  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...   8500.0   \n",
      "2868     NaN                                                NaN      NaN   \n",
      "2869  1441.0  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...   7250.0   \n",
      "2870     NaN                                                NaN      NaN   \n",
      "2871  1442.0        TOYOTA Corolla 1.6 LB LINEA TERRA 4/5-Doors   6950.0   \n",
      "\n",
      "      Age_08_04  Mfg_Month  Mfg_Year       KM     HP  Met_Color   Color  ...  \\\n",
      "0           NaN        NaN       NaN      NaN    NaN        NaN     NaN  ...   \n",
      "1          23.0       10.0    2002.0  46986.0   90.0        1.0    Blue  ...   \n",
      "2           NaN        NaN       NaN      NaN    NaN        NaN     NaN  ...   \n",
      "3          23.0       10.0    2002.0  72937.0   90.0        1.0  Silver  ...   \n",
      "4           NaN        NaN       NaN      NaN    NaN        NaN     NaN  ...   \n",
      "...         ...        ...       ...      ...    ...        ...     ...  ...   \n",
      "2867       71.0       10.0    1998.0  17016.0   86.0        0.0    Blue  ...   \n",
      "2868        NaN        NaN       NaN      NaN    NaN        NaN     NaN  ...   \n",
      "2869       70.0       11.0    1998.0  16916.0   86.0        1.0    Grey  ...   \n",
      "2870        NaN        NaN       NaN      NaN    NaN        NaN     NaN  ...   \n",
      "2871       76.0        5.0    1998.0      1.0  110.0        0.0   Green  ...   \n",
      "\n",
      "      Mistlamps  Sport_Model  Backseat_Divider  Metallic_Rim  Radio_cassette  \\\n",
      "0           NaN          NaN               NaN           NaN             NaN   \n",
      "1           0.0          0.0               1.0           0.0             0.0   \n",
      "2           NaN          NaN               NaN           NaN             NaN   \n",
      "3           0.0          0.0               1.0           0.0             0.0   \n",
      "4           NaN          NaN               NaN           NaN             NaN   \n",
      "...         ...          ...               ...           ...             ...   \n",
      "2867        0.0          0.0               1.0           0.0             0.0   \n",
      "2868        NaN          NaN               NaN           NaN             NaN   \n",
      "2869        0.0          0.0               1.0           0.0             0.0   \n",
      "2870        NaN          NaN               NaN           NaN             NaN   \n",
      "2871        0.0          0.0               0.0           0.0             0.0   \n",
      "\n",
      "      Parking_Assistant  Tow_Bar  CNG  Diesel  Petrol  \n",
      "0                   NaN      NaN    0       0       0  \n",
      "1                   0.0      0.0    0       1       0  \n",
      "2                   NaN      NaN    0       0       0  \n",
      "3                   0.0      0.0    0       1       0  \n",
      "4                   NaN      NaN    0       0       0  \n",
      "...                 ...      ...  ...     ...     ...  \n",
      "2867                0.0      0.0    0       0       1  \n",
      "2868                NaN      NaN    0       0       0  \n",
      "2869                0.0      0.0    0       0       1  \n",
      "2870                NaN      NaN    0       0       0  \n",
      "2871                0.0      0.0    0       0       1  \n",
      "\n",
      "[2872 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# convert the categorical data Fuel_type into dummy variables\n",
    "\n",
    "dummy_Fuel_Type=pd.get_dummies(toyotacorolla_df['Fuel_Type'])\n",
    "print(dummy_Fuel_Type.head(3))\n",
    "\n",
    "toyotacorolla_df=pd.concat([toyotacorolla_df, dummy_Fuel_Type], axis=1)\n",
    "\n",
    "toyotacorolla_df=toyotacorolla_df.rename(columns={1: 'CNG', 2: 'Diesel', 3: 'Petrol'})\n",
    "\n",
    "toyotacorolla_df=toyotacorolla_df.drop(['Fuel_Type'], axis=1)\n",
    "\n",
    "print(toyotacorolla_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id                                              Model    Price  \\\n",
      "1        1.0      TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13500.0   \n",
      "3        2.0      TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13750.0   \n",
      "5        3.0      TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  13950.0   \n",
      "7        4.0      TOYOTA Corolla 2.0 D4D HATCHB TERRA 2/3-Doors  14950.0   \n",
      "9        5.0        TOYOTA Corolla 2.0 D4D HATCHB SOL 2/3-Doors  13750.0   \n",
      "...      ...                                                ...      ...   \n",
      "2863  1438.0         TOYOTA Corolla 1.3 16V HATCHB G6 2/3-Doors   7500.0   \n",
      "2865  1439.0  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...  10845.0   \n",
      "2867  1440.0  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...   8500.0   \n",
      "2869  1441.0  TOYOTA Corolla 1.3 16V HATCHB LINEA TERRA 2/3-...   7250.0   \n",
      "2871  1442.0        TOYOTA Corolla 1.6 LB LINEA TERRA 4/5-Doors   6950.0   \n",
      "\n",
      "      Age_08_04  Mfg_Month  Mfg_Year       KM     HP  Met_Color   Color  ...  \\\n",
      "1          23.0       10.0    2002.0  46986.0   90.0        1.0    Blue  ...   \n",
      "3          23.0       10.0    2002.0  72937.0   90.0        1.0  Silver  ...   \n",
      "5          24.0        9.0    2002.0  41711.0   90.0        1.0    Blue  ...   \n",
      "7          26.0        7.0    2002.0  48000.0   90.0        0.0   Black  ...   \n",
      "9          30.0        3.0    2002.0  38500.0   90.0        0.0   Black  ...   \n",
      "...         ...        ...       ...      ...    ...        ...     ...  ...   \n",
      "2863       69.0       12.0    1998.0  20544.0   86.0        1.0    Blue  ...   \n",
      "2865       72.0        9.0    1998.0  19000.0   86.0        0.0    Grey  ...   \n",
      "2867       71.0       10.0    1998.0  17016.0   86.0        0.0    Blue  ...   \n",
      "2869       70.0       11.0    1998.0  16916.0   86.0        1.0    Grey  ...   \n",
      "2871       76.0        5.0    1998.0      1.0  110.0        0.0   Green  ...   \n",
      "\n",
      "      Mistlamps  Sport_Model  Backseat_Divider  Metallic_Rim  Radio_cassette  \\\n",
      "1           0.0          0.0               1.0           0.0             0.0   \n",
      "3           0.0          0.0               1.0           0.0             0.0   \n",
      "5           0.0          0.0               1.0           0.0             0.0   \n",
      "7           0.0          0.0               1.0           0.0             0.0   \n",
      "9           1.0          0.0               1.0           0.0             0.0   \n",
      "...         ...          ...               ...           ...             ...   \n",
      "2863        1.0          1.0               1.0           0.0             0.0   \n",
      "2865        0.0          1.0               1.0           0.0             0.0   \n",
      "2867        0.0          0.0               1.0           0.0             0.0   \n",
      "2869        0.0          0.0               1.0           0.0             0.0   \n",
      "2871        0.0          0.0               0.0           0.0             0.0   \n",
      "\n",
      "      Parking_Assistant  Tow_Bar  CNG  Diesel  Petrol  \n",
      "1                   0.0      0.0    0       1       0  \n",
      "3                   0.0      0.0    0       1       0  \n",
      "5                   0.0      0.0    0       1       0  \n",
      "7                   0.0      0.0    0       1       0  \n",
      "9                   0.0      0.0    0       1       0  \n",
      "...                 ...      ...  ...     ...     ...  \n",
      "2863                0.0      0.0    0       0       1  \n",
      "2865                0.0      0.0    0       0       1  \n",
      "2867                0.0      0.0    0       0       1  \n",
      "2869                0.0      0.0    0       0       1  \n",
      "2871                0.0      0.0    0       0       1  \n",
      "\n",
      "[1436 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# Removing missing values\n",
    "\n",
    "toyotacorolla_df=toyotacorolla_df.dropna(thresh=len(toyotacorolla_df.columns)-2)\n",
    "print(toyotacorolla_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(861, 17)\n"
     ]
    }
   ],
   "source": [
    "# separate out predictors and response variables\n",
    "\n",
    "X=toyotacorolla_df[['Age_08_04', 'KM', 'CNG', 'Diesel', 'Petrol', 'HP', 'Automatic', 'Doors', 'Quarterly_Tax', 'Mfr_Guarantee', 'Guarantee_Period', 'Airco', 'Automatic_airco',\n",
    "                   'CD_Player', 'Powered_Windows', 'Sport_Model', 'Tow_Bar']]\n",
    "y=toyotacorolla_df[['Price']]\n",
    "\n",
    "# partition data\n",
    "\n",
    "X_train, X_test, y_training, y_valid=train_test_split(X, y, test_size=0.4, random_state=12)\n",
    "print(X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we need to standardize both predictors and outcome or just one of thoese two?\n",
    "# Both the predictors and outcome need to be standardized. Like the outcome variable, price, many of the predictors are continuous variables.\n",
    "\n",
    "# Normalizing the outcome variable\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "y=scaler.fit_transform(y)\n",
    "y_training=scaler.fit_transform(y_training)\n",
    "y_valid=scaler.fit_transform(y_valid)\n",
    "\n",
    "# Normalizing the predictors\n",
    "\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train=scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=(5, 5), max_iter=500)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train neural network with 2 layers of 5 hidden nodes on each layer\n",
    "# don't forget to bring y_train back to a single array use dataframename.ravel() in the model fit.\n",
    "\n",
    "toyotacorolla_df_mlp=MLPRegressor(hidden_layer_sizes=(5, 5), max_iter=500)\n",
    "toyotacorolla_df_mlp.fit(X_train, y_training.ravel())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.6387179459598549\n",
      "-0.12107967278867449\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions on validation dataset.\n",
    "# compute model accuracy using .score()\n",
    "\n",
    "y_predict=toyotacorolla_df_mlp.predict(X_test)\n",
    "print(toyotacorolla_df_mlp.score(X_test, y_valid))\n",
    "print(toyotacorolla_df_mlp.score(X_train, y_training))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden layer 17 => 5\n",
      " Intercepts:\n",
      "  [-0.19087548 -0.06302096 -0.44331025  0.02796896 -0.43956634]\n",
      " Weights:\n",
      "  [-0.06686866  0.58084525 -0.12471296 -0.1193471   0.21900539]\n",
      "  [ 0.14886457  0.27358225 -0.01262114  0.35491901  0.23483677]\n",
      "  [ 0.57170609 -0.06242711  0.41156168  0.29996076 -0.13904494]\n",
      "  [ 0.01937211  0.25944857 -0.32927108  0.34061702 -0.17836413]\n",
      "  [-0.38266025 -0.0135512   0.24216167 -0.04947668  0.21607957]\n",
      "  [ 0.50830655  0.20874168  0.07193375  0.43968568 -0.23521125]\n",
      "  [ 0.4757383   0.14742105  0.43925083  0.40365603 -0.14830141]\n",
      "  [-0.14123879 -0.5070056  -0.28244357  0.24740461 -0.17147276]\n",
      "  [-0.21583205 -0.49695531  0.20610616 -0.33791636 -0.29920054]\n",
      "  [-0.14653752  0.34168422 -0.17842453 -0.14076667  0.22009073]\n",
      "  [ 0.0832011   0.39085617  0.13418838 -0.25518688  0.04039651]\n",
      "  [-0.03910949 -0.50595025  0.0742757  -0.33641944 -0.06847138]\n",
      "  [ 0.46734069 -0.04370006  0.35380588 -0.23330786  0.47162621]\n",
      "  [ 0.14001221 -0.36410391 -0.00801571 -0.2306153  -0.05223534]\n",
      "  [ 0.04051476 -0.16630192  0.05888866 -0.2415394  -0.17297284]\n",
      "  [-0.25002601 -0.32154407 -0.26603441  0.03797004 -0.11806664]\n",
      "  [-0.1140994   0.14039496 -0.14330234  0.15153371  0.26162609]\n",
      "\n",
      "Output layer 5 => 5\n",
      " Intercepts:\n",
      "  [0.3191343  0.26278194 0.6700737  0.52198484 0.79201605]\n",
      " Weights:\n",
      "  [-0.32598726  0.5803904   0.63817587 -0.24555458 -0.48609981]\n",
      "  [ 0.81489134  0.35691797 -0.14098562 -0.72919202 -0.25423928]\n",
      "  [-0.49085673 -0.20781409  0.30857512 -0.762474   -0.06266266]\n",
      "  [0.31284813 0.36429139 0.66866459 0.6957996  0.18310943]\n",
      "  [-0.32986333  0.38148997  0.54548161  0.60760052  0.01676403]\n",
      "\n",
      "Output layer 5 => 1\n",
      " Intercepts:\n",
      "  [0.85233935]\n",
      " Weights:\n",
      "  [-0.57836682]\n",
      "  [0.88087489]\n",
      "  [-0.58299505]\n",
      "  [0.54476121]\n",
      "  [-0.6493367]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Network structure\n",
    "# Hint: sample code given in in class exercise\n",
    "\n",
    "for i, (weights, intercepts) in enumerate(zip(toyotacorolla_df_mlp.coefs_, toyotacorolla_df_mlp.intercepts_)):\n",
    "    print('Hidden layer' if i == 0 else 'Output layer', '{0[0]} => {0[1]}'.format(weights.shape))\n",
    "    print(' Intercepts:\\n ', intercepts)\n",
    "    print(' Weights:')\n",
    "    for weight in weights:\n",
    "        print(' ', weight)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [575, 6]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13316/3903162053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# If you can, show us the print out. If you cannot, can you explain why?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m     \"\"\"\n\u001b[1;32m--> 299\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    300\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    320\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    321\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [575, 6]"
     ]
    }
   ],
   "source": [
    "# Can we print out the confusion_matrix and classification_report?\n",
    "# If you can, show us the print out. If you cannot, can you explain why?\n",
    "\n",
    "print(confusion_matrix(y_valid, predictions))\n",
    "print(classification_report(y_valid, predictions))\n",
    "\n",
    "#No, we cannot print out a confusion matrix and classification report when using a multi-layer perceptron regressor. I believe the reason is because the dependent variable\n",
    "# is continous and not categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret your results:\n",
    "\n",
    "# The model accuracy is pretty low. The score for the training set is -63, and the score for the validation set is -12. \n",
    "\n",
    "# Lesson learned from this excercise:\n",
    "# I learned created an MLR Regressor so that I could build a neural network. Given the model accuracy score and my lack of expertise on selling used Toyota\n",
    "# Corollas, it would probably take me awhile to create a better neural network. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
