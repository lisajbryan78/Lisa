{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Naive Bayes Classifier (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages for this chapter\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Personal Loan Acceptance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the universalbank.csv again for this assignemnt. \n",
    "\n",
    "The file universalbank.csv contains data on 5000 customers of Universal Bank. The data include customer demographic information (age, income, etc.), the customerâ€™s relationship with the bank (mortgage, securities account, etc.), and the customer response to the last personal loan campaign (Personal Loan). Among these 5000 customers, only 480 (= 9.6%) accepted the personal loan that was offered to them in the earlier campaign. In this exercise, we focus on three predictors: age, income, experience, and the outcome Personal Loan.\n",
    "\n",
    "Partition the data into training (60%) and validation (40%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Age  Experience  Income  Personal Loan\n",
      "0   25           1      49              0\n",
      "1   45          19      34              0\n",
      "2   39          15      11              0\n",
      "3   35           9     100              0\n",
      "4   35           8      45              0\n",
      "\n",
      " (5000, 4)\n",
      "\n",
      " Age              5000\n",
      "Experience       5000\n",
      "Income           5000\n",
      "Personal Loan    5000\n",
      "dtype: int64\n",
      "\n",
      "                Age   Experience       Income  Personal Loan\n",
      "count  5000.000000  5000.000000  5000.000000    5000.000000\n",
      "mean     45.338400    20.104600    73.774200       0.096000\n",
      "std      11.463166    11.467954    46.033729       0.294621\n",
      "min      23.000000    -3.000000     8.000000       0.000000\n",
      "25%      35.000000    10.000000    39.000000       0.000000\n",
      "50%      45.000000    20.000000    64.000000       0.000000\n",
      "75%      55.000000    30.000000    98.000000       0.000000\n",
      "max      67.000000    43.000000   224.000000       1.000000\n"
     ]
    }
   ],
   "source": [
    "# Load the data into band_df dataframe bank_df\n",
    "\n",
    "bank_df=pd.read_csv(\"C:/Users/lisaj/OneDrive/Documents/Documents/MIS 536/Module6Datasets/universalbank.csv\")\n",
    "\n",
    "# Only keep the columns we need: ncome, Experience, Age, Personal Loan.Drop the rest.\n",
    "\n",
    "bank_df=bank_df.drop(columns=['ID', 'ZIP Code', 'Family', 'CCAvg', 'Education', 'Mortgage', 'Securities Account', 'CD Account', 'Online', 'CreditCard'])\n",
    "\n",
    "\n",
    "# Use critical functions to explore the dataframe using print() to show results\n",
    "\n",
    "print('\\n', bank_df.head())\n",
    "print('\\n', bank_df.shape)\n",
    "print('\\n', bank_df.count())\n",
    "\n",
    "print('\\n', bank_df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Experience  Income  Personal_Loan\n",
      "0      25           1      49              0\n",
      "1      45          19      34              0\n",
      "2      39          15      11              0\n",
      "3      35           9     100              0\n",
      "4      35           8      45              0\n",
      "...   ...         ...     ...            ...\n",
      "4995   29           3      40              0\n",
      "4996   30           4      15              0\n",
      "4997   63          39      24              0\n",
      "4998   65          40      49              0\n",
      "4999   28           4      83              0\n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Does the data needs further cleaning?\n",
    "\n",
    "# Yes, the data needs further cleaning.\n",
    "\n",
    "# If you think so, write your clearning process here.\n",
    "\n",
    "bank_df=bank_df.rename(columns={'Personal Loan': 'Personal_Loan'})\n",
    "\n",
    "\n",
    "print(bank_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (3000, 4) Validation set: (2000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and validation sets\n",
    "\n",
    "\n",
    "train_df, valid_df=train_test_split(bank_df, test_size=0.4, random_state=1)\n",
    "print('Training set:', train_df.shape, 'Validation set:', valid_df.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Age  Experience  Income\n",
      "4522   31           5      29\n",
      "2851   61          36      81\n",
      "2313   58          32      54\n",
      "982    58          33      52\n",
      "1164   41          17      94 \n",
      "       Age  Experience  Income\n",
      "2764   31           5      84\n",
      "4767   35           9      45\n",
      "3814   34           9      35\n",
      "3499   49          23     114\n",
      "2735   36          12      70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the model the perform analysis\n",
    "\n",
    "outcome='Personal_Loan'\n",
    "X=list(bank_df.columns)\n",
    "X.remove(outcome)\n",
    "\n",
    "train_X=train_df[X]\n",
    "valid_X=valid_df[X]\n",
    "train_y=train_df[outcome]\n",
    "valid_y=valid_df[outcome]\n",
    "\n",
    "print(train_X.head(), \"\\n\", valid_X.head())\n",
    "\n",
    "classifier=GaussianNB()\n",
    "\n",
    "classifier.fit(train_X, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: [0 0 0 ... 0 0 0]\n",
      "\n",
      "Predicted Probability: [[9.72949978e-01 2.70500221e-02]\n",
      " [9.98913372e-01 1.08662825e-03]\n",
      " [9.99564824e-01 4.35175823e-04]\n",
      " ...\n",
      " [9.99966379e-01 3.36205279e-05]\n",
      " [9.99706813e-01 2.93187432e-04]\n",
      " [9.99424300e-01 5.75699971e-04]]\n",
      "      Age  Experience  Income         0         1  Predicted  Personal_Loan\n",
      "2764   31           5      84  0.972950  0.027050          0              0\n",
      "4767   35           9      45  0.998913  0.001087          0              0\n",
      "3814   34           9      35  0.999565  0.000435          0              0\n",
      "3499   49          23     114  0.862479  0.137521          0              0\n",
      "2735   36          12      70  0.991235  0.008765          0              0\n",
      "...   ...         ...     ...       ...       ...        ...            ...\n",
      "4372   34          10      41  0.999244  0.000756          0              0\n",
      "3401   39          15      28  0.999794  0.000206          0              0\n",
      "1239   51          26      12  0.999966  0.000034          0              0\n",
      "437    36           9      31  0.999707  0.000293          0              0\n",
      "415    35           8      38  0.999424  0.000576          0              0\n",
      "\n",
      "[2000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict the classification for test dataset\n",
    "\n",
    "predicted=classifier.predict(valid_X)\n",
    "predProb=classifier.predict_proba(valid_X)\n",
    "\n",
    "print(\"Predicted Value:\", predicted)\n",
    "print(\"\\nPredicted Probability:\", predProb)\n",
    "\n",
    "y_predict=classifier.predict(valid_X)\n",
    "y_predProb=classifier.predict_proba(valid_X)\n",
    "\n",
    "\n",
    "# Append your prediction, predicted probability to the testing dataset and print the new dataset out using print()\n",
    "# You should be able to view your prediction, observed outcome, and predictors for each data point side by side.\n",
    "\n",
    "predicted=pd.concat([valid_X, pd.DataFrame(y_predProb, index=valid_X.index)], axis=1)\n",
    "predicted=pd.concat([predicted, pd.DataFrame(y_predict, index=predicted.index, columns=[\"Predicted\"])], axis=1)\n",
    "predicted=pd.concat([predicted, pd.DataFrame(valid_y, index=predicted.index)], axis=1)\n",
    "\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.901\n"
     ]
    }
   ],
   "source": [
    "# calculate the accuracy of your prediction against the observed outcome.\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(valid_y, y_predict))\n",
    "\n",
    "\n",
    "# How well do you think the model does?\n",
    "\n",
    "# The model's prediction accuracy is 90%, which is pretty high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret your results:\n",
    "\n",
    "# The first result [[9.72949978e-01 2.70500221e-02] means that the person should not be given a loan since the predicted value is zero. There's a 97.3% chance that person should \n",
    "# be assigned to the class where he/she is not given a loan and a less than 1% chance that this person belongs to class 1 where he/she would be given a loan. The Gaussian model \n",
    "# created for this assignment is 90% accurate.\n",
    "\n",
    "# Lesson learned from this lab:\n",
    "\n",
    "# I used the Gaussian model to predict whether individuals in the bank dataframe would be given a personal loan based on the following predictors: age, experience, and income. The Gaussian\n",
    "# model is approoriate for this problem since there are just two outcomes and the predictors are continuous. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automobile Accidents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file accidents.csv contains information on 42,183 actual automobile accidents in 2001 in the United States that involved one of three levels of injury: NO INJURY, INJURY, or FATALITY. For each accident, additional information is recorded, such as day of week, weather conditions, and road type. A firm might be interested in developing a system for quickly classifying the severity of an accident based on three predictors: weather conditions (WEATHER_R), traffic conditions (TRAF_CON_R), and road type (INT_HWY).\n",
    "\n",
    "Our goal here is to predict whether an accident just reported will involve fatality (MAX_SEV_IR = 2), a non fetal injury (MAX_SEV_IR = 1) or not injury (MAX_SEV_IR = 0).\n",
    "\n",
    "Partition the data into training (80%) and validation (20%) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    INT_HWY  TRAF_CON_R  WEATHER_R  MAX_SEV_IR\n",
      "0        0           0          1           1\n",
      "1        1           0          2           0\n",
      "2        0           1          2           0\n",
      "3        0           1          1           0\n",
      "4        0           0          1           0\n",
      "\n",
      " (42183, 4)\n",
      "\n",
      " INT_HWY       42183\n",
      "TRAF_CON_R    42183\n",
      "WEATHER_R     42183\n",
      "MAX_SEV_IR    42183\n",
      "dtype: int64\n",
      "\n",
      "             INT_HWY    TRAF_CON_R     WEATHER_R    MAX_SEV_IR\n",
      "count  42183.000000  42183.000000  42183.000000  42183.000000\n",
      "mean       0.150321      0.516322      1.142783      0.519830\n",
      "std        0.418952      0.749417      0.349855      0.521256\n",
      "min        0.000000      0.000000      1.000000      0.000000\n",
      "25%        0.000000      0.000000      1.000000      0.000000\n",
      "50%        0.000000      0.000000      1.000000      1.000000\n",
      "75%        0.000000      1.000000      1.000000      1.000000\n",
      "max        9.000000      2.000000      2.000000      2.000000\n"
     ]
    }
   ],
   "source": [
    "# Load the data into band_df dataframe accidents_df\n",
    "\n",
    "accidents_df=pd.read_csv(\"C:/Users/lisaj/OneDrive/Documents/Documents/MIS 536/Module6Datasets/accidents.csv\")\n",
    "\n",
    "# Only keep the columns we need.Drop the rest.\n",
    "accidents_df=accidents_df.drop(columns=['HOUR_I_R', 'ALCHL_I', 'ALIGN_I', 'STRATUM_R', 'WRK_ZONE', 'WKDY_I_R', 'LGTCON_I_R', 'MANCOL_I_R', 'PED_ACC_R', 'RELJCT_I_R', 'REL_RWY_R', 'PROFIL_I_R', 'SPD_LIM', 'SUR_COND', 'TRAF_WAY', 'VEH_INVL', 'INJURY_CRASH', 'NO_INJ_I', 'PRPTYDMG_CRASH', 'FATALITIES'])\n",
    "\n",
    "# Use critical functions to explore the dataframe using print() to show results\n",
    "\n",
    "print('\\n', accidents_df.head())\n",
    "print('\\n', accidents_df.shape)\n",
    "print('\\n', accidents_df.count())\n",
    "\n",
    "print('\\n', accidents_df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (33746, 4) Validation set: (8437, 4)\n",
      "       INT_HWY  TRAF_CON_R  WEATHER_R\n",
      "41800        0           0          1\n",
      "34599        0           0          1\n",
      "37150        0           2          1\n",
      "11254        0           0          1\n",
      "18669        0           1          1 \n",
      "        INT_HWY  TRAF_CON_R  WEATHER_R\n",
      "36877        0           0          1\n",
      "34874        0           2          1\n",
      "41190        0           0          1\n",
      "38131        0           2          1\n",
      "30951        1           0          1\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into training set and test set: 80% training and 20% validation\n",
    "\n",
    "train_df, valid_df=train_test_split(accidents_df, test_size=0.2, random_state=109)\n",
    "\n",
    "print('Training set:', train_df.shape, 'Validation set:', valid_df.shape)\n",
    "\n",
    "outcome='MAX_SEV_IR'\n",
    "X=list(accidents_df.columns)\n",
    "X.remove(outcome)\n",
    "\n",
    "train_X=train_df[X]\n",
    "valid_X=valid_df[X]\n",
    "train_y=train_df[outcome]\n",
    "valid_y=valid_df[outcome]\n",
    "\n",
    "print(train_X.head(), \"\\n\", valid_X.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the model the perform analysis\n",
    "\n",
    "mnomial=MultinomialNB()\n",
    "mnomial.fit(train_X, train_y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       INT_HWY  TRAF_CON_R  WEATHER_R         0         1         2  \\\n",
      "36877        0           0          1  0.500996  0.487803  0.011201   \n",
      "34874        0           2          1  0.459190  0.533915  0.006895   \n",
      "41190        0           0          1  0.500996  0.487803  0.011201   \n",
      "38131        0           2          1  0.459190  0.533915  0.006895   \n",
      "30951        1           0          1  0.511824  0.471307  0.016869   \n",
      "...        ...         ...        ...       ...       ...       ...   \n",
      "22355        0           2          1  0.459190  0.533915  0.006895   \n",
      "22728        0           0          1  0.500996  0.487803  0.011201   \n",
      "9850         0           0          1  0.500996  0.487803  0.011201   \n",
      "10795        0           0          1  0.500996  0.487803  0.011201   \n",
      "21219        0           1          1  0.480231  0.510970  0.008799   \n",
      "\n",
      "       Predicted  MAX_SEV_IR  \n",
      "36877          0           1  \n",
      "34874          1           1  \n",
      "41190          0           1  \n",
      "38131          1           0  \n",
      "30951          0           0  \n",
      "...          ...         ...  \n",
      "22355          1           1  \n",
      "22728          0           1  \n",
      "9850           0           1  \n",
      "10795          0           1  \n",
      "21219          1           1  \n",
      "\n",
      "[8437 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# Predict the classification for test dataset\n",
    "\n",
    "y_predict=mnomial.predict(valid_X)\n",
    "y_predProb=mnomial.predict_proba(valid_X)\n",
    "\n",
    "\n",
    "# Append your prediction, predicted probability to the testing dataset and print the new dataset out using print()\n",
    "# You should be able to view your prediction, observed outcome, and predictors for each data point side by side.\n",
    "\n",
    "\n",
    "predicted=pd.concat([valid_X, pd.DataFrame(y_predProb, index=valid_X.index)], axis=1)\n",
    "predicted=pd.concat([predicted, pd.DataFrame(y_predict, index=predicted.index, columns=[\"Predicted\"])], axis=1)\n",
    "predicted=pd.concat([predicted, pd.DataFrame(valid_y, index=predicted.index)], axis=1)\n",
    "\n",
    "print(predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5121488680810715\n"
     ]
    }
   ],
   "source": [
    "# compute model accuracy of your prediction against observed outcomes.\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(valid_y, y_predict))\n",
    "\n",
    "\n",
    "# How well do you think the model does?\n",
    "\n",
    "# The model doesn't do a great job of prediction. It can only predict 51% of the classifications correctly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Credit: Can you improve the accuracy of the model to above 0.08 by finding a different set of the predictors?\n",
    "# Show you model below:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret your results:\n",
    "\n",
    "# Using the first result as an example, it is incorrect. The greatest probability, 50%, indicates that it will belong in class 0, \"no injurty.\" However, this accident was \n",
    "# actually categorized as '1', a \"nonfatal injury.\" Many other predictions in my model are incorrect since the model only predicts 51% of the classifications correctly. \n",
    "\n",
    "# Lesson learned from this lab:\n",
    "\n",
    "# The multinomial classifier is the model that was used in this exercise. It is appropriate to use since there are more than two outcomes possible in this model. The three possible\n",
    "# outcomes are 0=no injurty, 1-=nonfatal injury, 2=fatality. The classifiers used in this model are traffic conditions, weather conditions, and road type. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
